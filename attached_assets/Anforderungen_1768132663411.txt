Anforderung 1: Die FastAPI-Anwendung (main_fastapi.py)

Nutzung das Framework fastapi und den Server uvicorn.

Erstellung einen Endpunkt GET /items/{item_id}.

Wichtig: Der Endpunkt muss async definiert sein (async def read_item...).

Simulierung eine I/O-Operation (z.B. Datenbankabfrage) durch await asyncio.sleep(0.1) (100ms Wartezeit).

Ein JSON-Objekt zurückgeben: {"item_id": item_id, "framework": "FastAPI", "status": "success"}.

Den Code zusammenfügen, um die App mit uvicorn auf Port 8000 zu starten, wenn das Skript direkt ausgeführt wird.

Anforderung 2: Die Flask-Anwendung (main_flask.py)

Nutzung das Framework flask.

Erstellung denselben Endpunkt GET /items/<int:item_id>.

Definiere die Funktion synchron (def read_item...).

Simuliere dieselbe I/O-Operation blockierend durch time.sleep(0.1) (100ms Wartezeit).

Ein äquivalentes JSON-Objekt zurückgeben: {"item_id": item_id, "framework": "Flask", "status": "success"}.

Füge Code hinzu, um die App auf Port 8001 zu starten.

Anforderung 3: Das Benchmark-Skript (benchmark.sh)

Erstellung ein Shell-Skript, das das Tool wrk (oder alternativ ab - Apache Benchmark, falls wrk in der Replit-Umgebung nicht verfügbar ist) verwendet.

Das Skript soll nacheinander beide APIs testen.

Konfiguration für den Test:

Laufzeit: 30 Sekunden

Connections: 100

Threads (falls wrk): 4

Das Skript soll die Ergebnisse (Requests/sec, Latenz) in der Konsole ausgeben oder in eine Datei results.txt schreiben.

Zusätzliche Hinweise:

Erstelle eine requirements.txt mit allen notwendigen Abhängigkeiten (fastapi, uvicorn, flask, gunicorn).

Stelle sicher, dass die Flask-App im Benchmark idealerweise mit einem WSGI-Server wie gunicorn gestartet wird (z.B. mit 4 Workern), um ein realistisches Produktionsszenario zu simulieren, im Gegensatz zum integrierten Development-Server.

Bitte generiere den Code für alle genannten Dateien.